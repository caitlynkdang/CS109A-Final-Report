<!--Template: https://www.w3schools.com/bootstrap/tryit.asp?filename=trybs_temp_webpage&stacked=h-->
<!DOCTYPE html>
<html lang="en">
<head>
    <title>CS109A Final Report</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
    <style>
        /* Remove the navbar's default margin-bottom and rounded borders */
        .navbar {
            margin-bottom: 0;
            border-radius: 0;
        }

        /* Set height of the grid so .sidenav can be 100% (adjust as needed) */
        .row.content {height: 450px}

        /* Set gray background color and 100% height */
        .sidenav {
            padding-top: 20px;
            background-color: white;
            height: 100%;
        }

        /* Set black background color, white text and some padding */
        footer {
            background-color: #7DB840;
            color: white;
            padding: 15px;
        }

        /* On small screens, set height to 'auto' for sidenav and grid */
        @media screen and (max-width: 767px) {
            .sidenav {
                height: auto;
                padding: 15px;
            }
            .row.content {height:auto;}
        }
    </style>
</head>
<body>

<nav class="navbar navbar-inverse">
    <div class="container-fluid">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <img src="img/logo2.png" style="width:50px;height:50px;">
        </div>
        <div class="collapse navbar-collapse" id="myNavbar">
            <ul class="nav navbar-nav">
                <li><a href="index.html">Project Statement</a></li>
                <li><a href="data.html">Data Analysis</a></li>
                <li><a href="model.html">Model</a></li>
                <li class="active"><a href="results.html">Results</a></li>
                <li><a href="references.html">References</a></li>
            </ul>
        </div>
    </div>
</nav>

<div class="container-fluid text-center">
    <div class="row content">
        <div class="col-sm-2 sidenav"></div>
        <div class="col-sm-8 text-left">
            <h1>Result</h1>
            <h2>Calculating Accuracy</h2>
            Accuracy is found taking the overlap of the list of missing songs and the list of recommended songs to see and
            dividing it by the number of missing songs.
            <br>
            $${Accuracy = \frac{(\texttt{list of missing songs}) \cap (\texttt{list of recommended songs})}{\texttt{number of missing songs}}}$$

            <h2>Model: Layer 1 without weights</h2>
            This is the simpliest model we created. Finding the song overlaps between the input playlist and the training
            playlists and recommending over 300 songs as explained in the Model section. This model performed the best out
            of our three models. Our insights are explained in the other models.

            <li>Accuracy: 0.28</li>

            <h2>Model: Layer 1 with weights</h2>
            We tested Layer 1, including the weights for the number of followers the training playlists have. We see that
            this performed worse than without weights. We believe that this is because the number of followers are not
            indicative of how related the songs are within the playlist. For example, a "Throwback" playlist might be a
            list of songs before the year 2000 and another playlist "Top Pop Music" will be a collection of songs that
            are pop music. The songs within these playlists are similar to each other in a different way. One is by time
            period, and the other by genre. Since the type of playlists will likely to not match up to the input playlist,
            it doesn't make sense to put a weight to playlist that might skew a representation of a type of playlist (i.e.
            a genre based playlist vs. a time period playlist).

            <li>Accuracy: 0.16</li>

            <h2>Model: Layer 1 without weights + Layer 2</h2>
            For this model we tested was without the weights in Layer 1, since it performed worse, and adding
            Layer 2. We see that the accuracy score is still lower the first model. We hypothesize that
            this is because audio features/ attributes do not have a subjective layer that is necessary to
            recommend songs.

            <li>Accuracy: 0.21</li>

            <h2>Model: Layer 1 with weights + Layer 2</h2>
            The last model is with weights and layer 2. This modeled perform the worse out of all four models. We hypothesize
            that this model performed the worse based on the results we see from the two models above. We see that
            adding weights makes the model worse and adding layer 2 makes the model worse. It is not surprising that adding
            them both will have a negative affect on the model accuracy.

            <li>Accuracy: 0.12</li>


            <hr>
            <h1>Conclusion</h1>
            Prior to testing our models on the test dataset, we hypothesized that Layer 1 and Layer 2 combined would be the
            model with the highest accuracy because we were comparing not only playlist similarity, but also song similarity.
            At first, we were surprised with our results that the model with only Layer 1 and without weights performed the best.
            However, in hindsight we can see how Layer 2 fails to add a subjective layer to the recommender system because
            audio features are very objective metrics that people don't really use to select songs.
            <br><br>
            Overall, we do believe there is value in Layer 2 if we were to better select the attributes used. We discuss this below.

            <hr>
            <h1>Future Work</h1>
            A drawback from our model was that it was making several API calls that made the model super slow. An idea we had
            if we had the storage would be to store the song attributes for quick access.
            <br><br>
            In addition, we can look at different levels of similarity for the Spotify API Audio Features. For example, excluding
            some features that we believe would just add noise to the model.
            <br><br>
            We can also look into better ways to find similarity between the input playlist and the training playlists. Instead
            of simply finding song overlap, we could first categorize the playlists into different types (i.e. genre or time period).
            <br><br>
            There are several ways we can find similarities. If we had more time in the future, we would look into matching algorithms
            more and see if we could apply what we learn to our Music Recommender. We can also think about scaling the attributes
            to be on a specific scale, or weight certain attributes to be more or less by looking into which attributes
            are better indicators than others.
            <hr>

        </div>
        <div class="col-sm-2 sidenav"></div>
    </div>
</div>


</body>
</html>
